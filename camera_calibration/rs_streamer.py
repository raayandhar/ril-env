import pyrealsense2 as rs
import numpy as np
import cv2
from cv2 import aruco


class MarkSearch:

    def __init__(self):
        self.dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)
        self.parameters = aruco.DetectorParameters()

        self.detector = aruco.ArucoDetector(self.dictionary, self.parameters)

    def find_marker(self, frame):
        """
        Obtain marker id list from still image
        """
        # gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        # corners, ids, rejectedImgPoints = self.detector.detectMarkers(gray)

        # if ids is None:
        #     return (None,None),None

        # ids = ids.flatten()

        # # loop over the detected ArUCo corners
        # for (markerCorner, markerID) in zip(corners, ids):
        #     # extract the marker corners (which are always returned in
        #     # top-left, top-right, bottom-right, and bottom-left order)
        #     corners = markerCorner.reshape((4, 2))
        #     (topLeft, topRight, bottomRight, bottomLeft) = corners
        #     # convert each of the (x, y)-coordinate pairs to integers

        #     #u = np.mean((topLeft[0], bottomRight[0])).astype(int)
        #     #v = np.mean((topLeft[1], bottomRight[1])).astype(int)
        #     u = np.mean((topLeft[0], bottomRight[0]))
        #     v = np.mean((topLeft[1], bottomRight[1]))

        #     cv2.circle(image, (int(u),int(v)), 5, (0,0,255), -1)
        #     cv2.imshow("rgb", image)
        #     cv2.waitKey(1)

        #     return (u,v), image

        # 1- convert frame from BGR to HSV
        HSV = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

        # 2- define the range of red
        lower = np.array([-10, 100, 100])
        upper = np.array([10, 255, 255])

        # check if the HSV of the frame is lower or upper red
        Red_mask = cv2.inRange(HSV, lower, upper)
        result = cv2.bitwise_and(frame, frame, mask=Red_mask)

        # Draw rectangular bounded line on the detected red area
        (contours, _) = cv2.findContours(
            Red_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE
        )
        for _, contour in enumerate(contours):
            area = cv2.contourArea(contour)
            if area > 300:  # to remove the noise
                # Constructing the size of boxes to be drawn around the detected red area
                x, y, w, h = cv2.boundingRect(contour)
                # frame = cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)
                frame = cv2.circle(
                    frame,
                    (int(x + w / 2), int(y + h / 2)),
                    radius=5,
                    color=(255, 0, 0),
                    thickness=-1,
                )

                u = int(x + w / 2)
                v = int(y + h / 2)
                return (u, v), frame
        return (None, None), None


class RealsenseStreamer:
    def __init__(self, serial_no=None):

        # in-hand : 317222072157
        # external: 317422075456

        # Configure depth and color streams
        self.pipeline = rs.pipeline()

        self.config = rs.config()

        if serial_no is not None:
            self.config.enable_device(serial_no)

        self.width = 640
        self.height = 480

        self.config.enable_stream(
            rs.stream.color, self.width, self.height, rs.format.bgr8, 30
        )
        self.config.enable_stream(
            rs.stream.depth, self.width, self.height, rs.format.z16, 30
        )

        self.align_to_color = rs.align(rs.stream.color)

        # Start streaming
        self.pipe_profile = self.pipeline.start(self.config)

        profile = self.pipeline.get_active_profile()

        ## Configure depth sensor settings
        depth_sensor = profile.get_device().query_sensors()[0]
        depth_sensor.set_option(rs.option.enable_auto_exposure, 1)
        depth_sensor.set_option(rs.option.depth_units, 0.001)
        preset_range = depth_sensor.get_option_range(rs.option.visual_preset)
        for i in range(int(preset_range.max)):
            visualpreset = depth_sensor.get_option_value_description(
                rs.option.visual_preset, i
            )
            if visualpreset == "Default":
                depth_sensor.set_option(rs.option.visual_preset, i)

        color_sensor = profile.get_device().query_sensors()[1]
        color_sensor.set_option(rs.option.enable_auto_exposure, 1)

        self.serial_no = serial_no

        if self.serial_no == "317422075456":
            color_sensor.set_option(rs.option.exposure, 140)

        # Intrinsics & Extrinsics
        frames = self.pipeline.wait_for_frames()
        frames = self.align_to_color.process(frames)

        depth_frame = frames.get_depth_frame()
        color_frame = frames.get_color_frame()

        self.depth_intrin = depth_frame.profile.as_video_stream_profile().intrinsics
        self.color_intrin = color_frame.profile.as_video_stream_profile().intrinsics

        self.depth_to_color_extrin = depth_frame.profile.get_extrinsics_to(
            color_frame.profile
        )
        self.colorizer = rs.colorizer()

        self.K = np.array(
            [
                [self.depth_intrin.fx, 0, self.depth_intrin.ppx],
                [0, self.depth_intrin.fy, self.depth_intrin.ppy],
                [0, 0, 1],
            ]
        )

        self.dec_filter = rs.decimation_filter()
        self.spat_filter = rs.spatial_filter()
        self.temp_filter = rs.temporal_filter()
        self.hole_filling_filter = rs.hole_filling_filter()

    def deproject(self, px, depth_frame):
        u, v = px
        depth = depth_frame.get_distance(u, v)
        xyz = rs.rs2_deproject_pixel_to_point(self.depth_intrin, [u, v], depth)
        return xyz

    def capture_rgb(self):
        color_frame = None
        while True:
            frames = self.pipeline.wait_for_frames()
            color_frame = frames.get_color_frame()
            if color_frame is not None:
                color_image = np.asanyarray(color_frame.get_data())
                break
        return color_image

    def filter_depth(self, depth_frame):
        # filtered = self.dec_filter.process(depth_frame)
        # filtered = self.spat_filter.process(filtered)

        filtered = depth_frame
        # filtered = self.hole_filling_filter.process(filtered)
        # filtered = self.temp_filter.process(filtered)
        # filtered = self.spat_filter.process(filtered)
        return filtered.as_depth_frame()

    def capture_rgbd(self):
        frame_error = True
        while frame_error:
            try:
                frames = self.align_to_color.process(frames)
                depth_frame = frames.get_depth_frame()
                color_frame = frames.get_color_frame()
                frame_error = False
            except:
                frames = self.pipeline.wait_for_frames()
                continue
        color_image = np.asanyarray(color_frame.get_data())
        depth_frame = self.filter_depth(depth_frame)
        depth_image = np.asanyarray(self.colorizer.colorize(depth_frame).get_data())
        return color_frame, color_image, depth_frame, depth_image

    def stop_stream(self):
        self.pipeline.stop()

    def show_image(self, image):
        cv2.imshow("img", image)
        cv2.waitKey(0)


if __name__ == "__main__":
    # realsense_streamer  = RealsenseStreamer('317222072157')
    realsense_streamer = RealsenseStreamer("317422075456")  # 317422074281 small
    marker_search = MarkSearch()

    frames = []
    while True:
        _, rgb_image, depth_frame, depth_img = realsense_streamer.capture_rgbd()
        cv2.waitKey(1)
        cv2.imshow("img", rgb_image)
        (u, v), vis = marker_search.find_marker(rgb_image)
        print(u, v)
        cv2.imshow("img", np.hstack((depth_img, vis)))
